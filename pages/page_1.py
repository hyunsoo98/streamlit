import streamlit as st
from google.cloud import vision
import io
import os
import json
import re
import pandas as pd
import numpy as np
from joblib import load # ëª¨ë¸ ë¡œë“œë¥¼ ìœ„í•´ joblib ì„í¬íŠ¸

# st.set_page_configëŠ” app.pyì—ì„œ ì´ë¯¸ í˜¸ì¶œë˜ì—ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œê±°í•©ë‹ˆë‹¤.
# st.set_page_config(page_title="ì´ë¯¸ì§€ ê±´ê°• ë°ì´í„° ì¶”ì¶œ ë° ë¶„ì„", layout="centered")

# --- Vision API í´ë¼ì´ì–¸íŠ¸ì™€ ì„ì‹œ ì¸ì¦ íŒŒì¼ ê²½ë¡œë¥¼ session_stateì—ì„œ ê°€ì ¸ì˜¤ê¸° ---
# app.pyì—ì„œ ì´ˆê¸°í™”ëœ clientë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
vision_client = st.session_state.get('vision_client')
temp_credentials_path = st.session_state.get('temp_credentials_path')

# í´ë¼ì´ì–¸íŠ¸ê°€ ì œëŒ€ë¡œ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ
if vision_client is None:
    st.error("Google Cloud Vision API í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë©”ì¸ í˜ì´ì§€ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì•±ì„ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- DB ì„¤ì • ë° í•¨ìˆ˜ (ì´ë¯¸ì§€ ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ìš©) - ì œê±°ë¨ ---
# ì´ ë¶€ë¶„ì€ ì´ ìš”ì²­ì—ì„œ í•„ìš”í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°í•©ë‹ˆë‹¤.
# DB_FILE_IMAGE_RESULTS = "image_results.db"
# def init_image_results_db(): ...
# def save_image_result(...): ...
# if 'image_results_db_initialized' not in st.session_state: ...

# --- Creatie.ai CSS ì ìš© ì‹œì‘ - ì œê±°ë¨ ---
# app.pyì—ì„œ ì „ì—­ì ìœ¼ë¡œ CSSë¥¼ ì ìš©í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œê±°í•©ë‹ˆë‹¤.
# def apply_creatie_css(): ...
# apply_creatie_css()

# Google Cloud ì¸ì¦ ì •ë³´ ì„¤ì • (ì´ë¯¸ app.pyì—ì„œ ì²˜ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œê±°)
# try: ... except Exception as e: ...
# client = get_vision_client() (-> vision_clientë¡œ ë³€ê²½ë˜ì—ˆê³ , app.pyì—ì„œ ê°€ì ¸ì˜´)

# --- í…ìŠ¤íŠ¸ íŒŒì‹± í•¨ìˆ˜ ---
def parse_health_data_from_ocr(text):
    data = {}

    # ë‚˜ì´ ë° ì„±ë³„ íŒŒì‹±
    age_gender_match = re.search(r'ë‚˜ì´ì„±ë³„\s*(\d+)\s*(ì—¬ì„±|ë‚¨ì„±)', text)
    if age_gender_match:
        data['ë‚˜ì´'] = int(age_gender_match.group(1))
        data['ì„±ë³„'] = age_gender_match.group(2).strip()
    else:
        data['ë‚˜ì´'] = None
        data['ì„±ë³„'] = None

    # í‚¤ ë° ëª¸ë¬´ê²Œ íŒŒì‹± (ê´„í˜¸ ì´ìŠ¤ì¼€ì´í”„ ìˆ˜ì •)
    height_weight_match = re.search(r'í‚¤\(cm\)/ëª¸ë¬´ê²Œ\(kg\)\s*(\d+)\(cm\)/(\d+)\(kg\)', text)
    if height_weight_match:
        data['ì‹ ì¥'] = int(height_weight_match.group(1))
        data['ì²´ì¤‘'] = int(height_weight_match.group(2))
    else:
        data['ì‹ ì¥'] = None
        data['ì²´ì¤‘'] = None

    # í˜ˆì•• íŒŒì‹± (ê³ í˜ˆì••' í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ì§€ ì•Šê³  íŒ¨í„´ ì°¾ê¸°)
    bp_match = re.search(r'(\d+)/(\d+)\s*mmHg', text)
    if bp_match:
        data['ìˆ˜ì¶•ê¸° í˜ˆì••'] = int(bp_match.group(1))
        data['ì´ì™„ê¸° í˜ˆì••'] = int(bp_match.group(2))
    else:
        data['ìˆ˜ì¶•ê¸° í˜ˆì••'] = None
        data['ì´ì™„ê¸° í˜ˆì••'] = None

    patterns = {
        'í˜ˆìƒ‰ì†Œ': r'í˜ˆìƒ‰ì†Œ\(g/dL\)\s*(\d+(\.\d+)?)',
        'ê³µë³µ í˜ˆë‹¹': r'ê³µë³µí˜ˆë‹¹\(mg/dL\)\s*(\d+(\.\d+)?)',
        'ì´ ì½œë ˆìŠ¤í…Œë¡¤': r'ì´ì½œë ˆìŠ¤í…Œë¡¤\(mg/dL\)\s*(\d+(\.\d+)?)',
        'HDL ì½œë ˆìŠ¤í…Œë¡¤': r'ê³ ë°€ë„ ì½œë ˆìŠ¤í…Œë¡¤\(mg/dL\)\s*(\d+(\.\d+)?)',
        'íŠ¸ë¦¬ê¸€ë¦¬ì„¸ë¼ì´ë“œ': r'ì¤‘ì„±ì§€ë°©\(mg/dL\)\s*(\d+(\.\d+)?)',
        'LDL ì½œë ˆìŠ¤í…Œë¡¤': r'ì €ë°€ë„ ì½œë ˆìŠ¤í…Œë¡¤\(mg/dL\)\s*(\d+(\.\d+)?)',
        'í˜ˆì²­ í¬ë ˆì•„í‹°ë‹Œ': r'í˜ˆì²­ í¬ë ˆì•„í‹°ë‹Œ\(mg/dL\)\s*(\d+(\.\d+)?)',
        'AST': r'AST\(SGOT\)\(IU/L\)\s*(\d+(\.\d+)?)',
        'ALT': r'ALT\(SGPT\)\(IU/L\)\s*(\d+(\.\d+)?)',
        'ê°ë§ˆì§€í‹°í”¼': r'ê°ë§ˆì§€í‹°í”¼\(XGTP\)\(IU/L\)\s*(\d+(\.\d+)?)',
        'ìš”ë‹¨ë°±': r'ìš”ë‹¨ë°±\s*([ê°€-í£]+)',
        'í¡ì—° ìƒíƒœ': None,
        'ìŒì£¼ ì—¬ë¶€': None
    }

    for key, pattern in patterns.items():
        if pattern is None:
            data[key] = None
            continue

        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
        if match:
            value_str = match.group(1)
            try:
                data[key] = float(value_str)
            except ValueError:
                data[key] = value_str.strip()
            except IndexError:
                try:
                    start_index = match.end()
                    rest_of_text = text[start_index:].splitlines()[0].strip()
                    num_match = re.search(r'\d+(\.\d+)?', rest_of_text)
                    if num_match:
                        data[key] = float(num_match.group(0))
                    else:
                        data[key] = None
                except Exception:
                    data[key] = None
        else:
            data[key] = None
    return data

# --- í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ ---
def preprocess_and_engineer_features(raw_data):
    processed_data = {}

    processed_data['ì‹ì „í˜ˆë‹¹(ê³µë³µí˜ˆë‹¹)'] = raw_data.get('ê³µë³µ í˜ˆë‹¹')
    processed_data['ì´ì½œë ˆìŠ¤í…Œë¡¤'] = raw_data.get('ì´ ì½œë ˆìŠ¤í…Œë¡¤')
    processed_data['í˜ˆìƒ‰ì†Œ'] = raw_data.get('í˜ˆìƒ‰ì†Œ')
    processed_data['í˜ˆì²­í¬ë ˆì•„í‹°ë‹Œ'] = raw_data.get('í˜ˆì²­ í¬ë ˆì•„í‹°ë‹Œ')
    processed_data['ê°ë§ˆì§€í‹°í”¼'] = raw_data.get('ê°ë§ˆì§€í‹°í”¼')
    processed_data['ìš”ë‹¨ë°±'] = raw_data.get('ìš”ë‹¨ë°±')

    gender = raw_data.get('ì„±ë³„')
    if gender == 'ë‚¨ì„±':
        processed_data['ì„±ë³„ì½”ë“œ'] = 1
    elif gender == 'ì—¬ì„±':
        processed_data['ì„±ë³„ì½”ë“œ'] = 2
    else:
        processed_data['ì„±ë³„ì½”ë“œ'] = np.nan

    processed_data['í¡ì—°ìƒíƒœ'] = 1 # ì˜ˆì‹œë¡œ ë¹„í¡ì—°ì(1) ì„¤ì •

    age = raw_data.get('ë‚˜ì´')
    if age is not None:
        processed_data['ì—°ë ¹ëŒ€ì½”ë“œ(5ì„¸ë‹¨ìœ„)'] = (age // 5) * 5
    else:
        processed_data['ì—°ë ¹ëŒ€ì½”ë“œ(5ì„¸ë‹¨ìœ„)'] = np.nan

    # ì‹œë ¥(í‰ê· )ì€ OCRì—ì„œ ì¶”ì¶œë˜ì§€ ì•Šìœ¼ë¯€ë¡œ NaN ì²˜ë¦¬
    processed_data['ì‹œë ¥(í‰ê· )'] = np.nan

    height = raw_data.get('ì‹ ì¥')
    weight = raw_data.get('ì²´ì¤‘')
    if height is not None and weight is not None and height > 0:
        processed_data['bmi'] = weight / ((height / 100.0) ** 2)
    else:
        processed_data['bmi'] = np.nan

    # íŒŒìƒ ë³€ìˆ˜ ê³„ì‚°
    alt = processed_data.get('alt') if processed_data.get('alt') is not None else raw_data.get('ALT')
    ast = processed_data.get('ast') if processed_data.get('ast') is not None else raw_data.get('AST')
    if alt is not None and ast is not None and ast != 0:
        processed_data['alt_ast_ratio'] = alt / ast
    else:
        processed_data['alt_ast_ratio'] = np.nan

    triglycerides = processed_data.get('triglycerides') if processed_data.get('triglycerides') is not None else raw_data.get('íŠ¸ë¦¬ê¸€ë¦¬ì„¸ë¼ì´ë“œ')
    hdl = processed_data.get('hdl_cholesterol') if processed_data.get('hdl_cholesterol') is not None else raw_data.get('HDL ì½œë ˆìŠ¤í…Œë¡¤')
    if triglycerides is not None and hdl is not None and hdl != 0:
        processed_data['tg_hdl_ratio'] = triglycerides / hdl
    else:
        processed_data['tg_hdl_ratio'] = np.nan

    ggtp = processed_data.get('gamma_gtp') if processed_data.get('gamma_gtp') is not None else raw_data.get('ê°ë§ˆì§€í‹°í”¼')
    alt = processed_data.get('alt') if processed_data.get('alt') is not None else raw_data.get('ALT')
    if ggtp is not None and alt is not None and alt != 0:
        processed_data['ggtp_alt_ratio'] = ggtp / alt
    else:
        processed_data['ggtp_alt_ratio'] = np.nan

    ldl = processed_data.get('ldl_cholesterol') if processed_data.get('ldl_cholesterol') is not None else raw_data.get('LDL ì½œë ˆìŠ¤í…Œë¡¤')
    hdl = processed_data.get('hdl_cholesterol') if processed_data.get('hdl_cholesterol') is not None else raw_data.get('HDL ì½œë ˆìŠ¤í…Œë¡¤')
    if ldl is not None and hdl is not None and hdl != 0:
        processed_data['ldl_hdl_ratio'] = ldl / hdl
    else:
        processed_data['ldl_hdl_ratio'] = np.nan

    # `04_modeling.ipynb`ì˜ `df.columns`ì—ì„œ í™•ì¸ëœ í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ (íƒ€ê²Ÿ ì œì™¸)
    required_features_from_notebook = [
        'ì„±ë³„ì½”ë“œ', 'ì—°ë ¹ëŒ€ì½”ë“œ(5ì„¸ë‹¨ìœ„)', 'ì‹œë ¥(í‰ê· )', 'ì‹ì „í˜ˆë‹¹(ê³µë³µí˜ˆë‹¹)', 'ì´ì½œë ˆìŠ¤í…Œë¡¤', 'í˜ˆìƒ‰ì†Œ', 'ìš”ë‹¨ë°±',
        'í˜ˆì²­í¬ë ˆì•„í‹°ë‹Œ', 'ê°ë§ˆì§€í‹°í”¼', 'í¡ì—°ìƒíƒœ', 'ìŒì£¼ì—¬ë¶€', 'bmi', 'alt_ast_ratio',
        'tg_hdl_ratio', 'ggtp_alt_ratio', 'ldl_hdl_ratio'
    ]

    for feature in required_features_from_notebook:
        if feature not in processed_data:
            if feature == 'ìš”ë‹¨ë°±':
                processed_data[feature] = None
            elif feature == 'ìŒì£¼ì—¬ë¶€':
                processed_data[feature] = None
            else:
                processed_data[feature] = np.nan

    # 'ìš”ë‹¨ë°±' ê°’ì„ ëª¨ë¸ì— ë§ê²Œ ë³€í™˜ (ì •ìƒ -> 0)
    if processed_data.get('ìš”ë‹¨ë°±') == 'ì •ìƒ':
        processed_data['ìš”ë‹¨ë°±'] = 0
    else:
        processed_data['ìš”ë‹¨ë°±'] = np.nan

    return processed_data

def prepare_model_input(processed_data, model_features_order):
    df_sample = pd.DataFrame([processed_data])

    try:
        # 04_modeling.ipynbì˜ `numeric_features` ì •ì˜ë¥¼ ì°¸ê³ í•˜ì—¬ ì»¬ëŸ¼ ì„ íƒ
        # ì´ë“¤ì€ StandardScalerë¥¼ í†µê³¼í•˜ëŠ” í”¼ì²˜ë“¤ì…ë‹ˆë‹¤.
        numeric_features = [
            'ì—°ë ¹ëŒ€ì½”ë“œ(5ì„¸ë‹¨ìœ„)', 'ì‹œë ¥(í‰ê· )', 'ì‹ì „í˜ˆë‹¹(ê³µë³µí˜ˆë‹¹)', 'í˜ˆìƒ‰ì†Œ', 'ìš”ë‹¨ë°±',
            'í˜ˆì²­í¬ë ˆì•„í‹°ë‹Œ', 'ê°ë§ˆì§€í‹°í”¼', 'bmi', 'alt_ast_ratio', 'tg_hdl_ratio',
            'ggtp_alt_ratio', 'ldl_hdl_ratio'
        ]

        df_model_input = df_sample[numeric_features].copy()

        for col in df_model_input.columns:
            df_model_input[col] = pd.to_numeric(df_model_input[col], errors='coerce')

        return df_model_input

    except KeyError as e:
        st.error(f"ì˜¤ë¥˜: ëª¨ë¸ì— í•„ìš”í•œ í”¼ì²˜ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤: {e}")
        st.write(f"ë°ì´í„°ì— ìˆëŠ” í”¼ì²˜: {df_sample.columns.tolist()}")
        st.write(f"ì˜ˆìƒë˜ëŠ” í”¼ì²˜ ìˆœì„œ (numeric_features): {model_features_order}")
        return None
    except Exception as e:
        st.error(f"ëª¨ë¸ ì…ë ¥ ë°ì´í„° ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def classify_risk_level(prediction_proba):
    if prediction_proba is None:
        return "ë¶„ë¥˜ ë¶ˆê°€"

    # 04_modeling.ipynbì—ì„œ Threshold 0.48ë¡œ ì¡°ì •ë˜ì—ˆìœ¼ë¯€ë¡œ, ì´ë¥¼ ë°˜ì˜í•˜ì—¬ ë¶„ë¥˜
    # ì´ ë¶„ë¥˜ ë¡œì§ì€ ì˜ˆì¸¡ í™•ë¥ ì„ 4ë‹¨ê³„ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì´ë¯€ë¡œ, 0.48ì€ 'ì •ìƒ'ê³¼ 'ì£¼ì˜'ë¥¼ ë‚˜ëˆ„ëŠ” ê¸°ì¤€ìœ¼ë¡œë§Œ ì ìš©
    if prediction_proba < 0.48:
        return "ì •ìƒ"
    elif prediction_proba <= 0.59:
        return "ì£¼ì˜"
    elif prediction_proba <= 0.74:
        return "ìœ„í—˜"
    else:
        return "ê³ ìœ„í—˜"

# ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ ìµœì¢… í”¼ì²˜ ëª©ë¡ ë° ìˆœì„œëŠ” `prepare_model_input` ë‚´ `numeric_features`ì— ëª…ì‹œë¨
# ì´ ë³€ìˆ˜ëŠ” ì´ì œ ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°í•©ë‹ˆë‹¤.
# model_features_order = [...]


# --- Streamlit ì•± ë©”ì¸ ë¡œì§ ---
st.title("Google Cloud Vision APIë¥¼ ì´ìš©í•œ ì´ë¯¸ì§€ ê±´ê°• ë°ì´í„° ì¶”ì¶œ ë° ë¶„ì„")
st.write("ê±´ê°•ê²€ì§„ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ Vision APIë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ , ì¶”ì¶œëœ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê³ í˜ˆì•• ìœ„í—˜ë„ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
st.write("âš ï¸ **ì£¼ì˜:** ì´ ì•±ì€ ì˜ˆì‹œ ëª©ì ìœ¼ë¡œ, ì‹¤ì œ ì˜ë£Œ ì§„ë‹¨ì— ì‚¬ìš©ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ˆì¸¡ ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤.")

# ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ (ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¡œë“œí•˜ë„ë¡ ìºì‹œ)
@st.cache_resource
def load_prediction_assets():
    model_path = 'model/logistic_model.pkl'
    scaler_path = 'model/scaler.pkl'

    loaded_model = None
    loaded_scaler = None

    if os.path.exists(model_path) and os.path.exists(scaler_path):
        try:
            loaded_model = load(model_path)
            loaded_scaler = load(scaler_path)
            st.success(f"ëª¨ë¸({model_path}) ë° ìŠ¤ì¼€ì¼ëŸ¬({scaler_path})ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return loaded_model, loaded_scaler
        except Exception as e:
            st.error(f"ëª¨ë¸ ë˜ëŠ” ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.warning("ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ë²„ì „ìœ¼ë¡œ ì €ì¥ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return None, None
    else:
        st.warning(f"ëª¨ë¸ ë˜ëŠ” ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸: {model_path}, ìŠ¤ì¼€ì¼ëŸ¬: {scaler_path}")
        st.write("ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ê³  ì•±ê³¼ ê°™ì€ ìœ„ì¹˜ ë˜ëŠ” ì ‘ê·¼ ê°€ëŠ¥í•œ ê²½ë¡œì— ë‘ì„¸ìš”.")
        return None, None

loaded_model, loaded_scaler = load_prediction_assets()

# ì´ë¯¸ì§€ ì—…ë¡œë“œ ìœ„ì ¯
uploaded_file = st.file_uploader("ê±´ê°•ê²€ì§„ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”...", type=["jpg", "jpeg", "png", "gif", "bmp"])

# ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ë©´ ì²˜ë¦¬ ì‹œì‘
if uploaded_file is not None and vision_client is not None:
    st.image(uploaded_file, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)
    st.write("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")

    try:
        image_content = uploaded_file.read()
        image = vision.Image(content=image_content)
        response = vision_client.document_text_detection(image=image)
        texts = response.full_text_annotation

        if texts and texts.text:
            st.subheader("1. Vision API ì¶”ì¶œ í…ìŠ¤íŠ¸:")
            st.text_area("ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸", texts.text, height=300)

            st.subheader("2. í…ìŠ¤íŠ¸ íŒŒì‹± ê²°ê³¼:")
            raw_health_data = parse_health_data_from_ocr(texts.text)
            st.json(raw_health_data)

            st.subheader("3. ë°ì´í„° ì „ì²˜ë¦¬ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê²°ê³¼:")
            processed_health_data = preprocess_and_engineer_features(raw_health_data)
            st.json(processed_health_data)

            st.subheader("4. ëª¨ë¸ ì…ë ¥ ë°ì´í„° ì¤€ë¹„:")
            # model_features_order ë³€ìˆ˜ ì œê±°
            model_input_df = prepare_model_input(processed_health_data, []) # model_features_orderëŠ” ì´ì œ prepare_model_input ë‚´ë¶€ì—ì„œ ì •ì˜

            if model_input_df is not None and not model_input_df.empty: # DataFrameì´ ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸
                st.dataframe(model_input_df)

                st.subheader("5. ê³ í˜ˆì•• ìœ„í—˜ ì˜ˆì¸¡:")
                if loaded_model is not None and loaded_scaler is not None:
                    try:
                        scaled_input = loaded_scaler.transform(model_input_df)
                        prediction_proba = loaded_model.predict_proba(scaled_input)[:, 1]
                        st.write(f"ì˜ˆì¸¡ëœ ê³ í˜ˆì•• í™•ë¥ : **{prediction_proba[0]:.4f}**")

                        risk_level = classify_risk_level(prediction_proba[0])
                        st.write(f"ê³ í˜ˆì•• ìœ„í—˜ ë“±ê¸‰: **{risk_level}**")

                        # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ session_stateì— ì €ì¥í•˜ì—¬ page_2.pyë¡œ ì „ë‹¬
                        st.session_state['prediction_proba'] = prediction_proba[0]
                        st.session_state['risk_level'] = risk_level

                        st.page_link("pages/page_2.py", label="ê²°ê³¼ ë³´ê¸°", icon="ğŸ“ˆ")

                    except Exception as e:
                        st.error(f"ëª¨ë¸ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        st.warning("ëª¨ë¸ ì…ë ¥ ë°ì´í„°ì˜ í˜•ì‹ì´ë‚˜ í”¼ì²˜ê°€ ëª¨ë¸ì˜ ê¸°ëŒ€ì¹˜ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ëª¨ë¸ ë˜ëŠ” ìŠ¤ì¼€ì¼ëŸ¬ê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("ëª¨ë¸ ì…ë ¥ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨ ë˜ëŠ” ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if response.error.message:
            st.error(f"Vision API ì˜¤ë¥˜ ë°œìƒ: {response.error.message}")

    except Exception as e:
        st.error(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ë˜ëŠ” ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

st.markdown("---")
st.write("ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ Google Cloud Vision API ë° ì œê³µëœ ë°ì´í„° ì²˜ë¦¬ ë¡œì§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# ì„ì‹œ ì¸ì¦ íŒŒì¼ ì‚­ì œ (app.pyì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œê±°)
# if temp_credentials_path and os.path.exists(temp_credentials_path): ...
